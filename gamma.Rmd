---
title: "LISA - Gamma specification"
author: "Fabien Petit"
output: 
  github_document:	
    pandoc_args: --webtex
---

## Data

Data are from Penn World Table 9.1, OECD Database and United Nations (World Population Prospects).

```{r Initialization, include = FALSE}

# Define paths
loc_result = file.path(getwd(), "result")
loc_sim = file.path(loc_result, "sim")
loc_function = file.path(getwd(), "function")
loc_final = file.path(getwd(), "data", "final")

# Load packages
packages <- c("bucky", "dplyr", "ggplot2", "ggrepel", "lmtest", "sandwich", "zoo", "RColorBrewer", "reshape2")
lapply(packages, require, character.only = TRUE)
rm(packages)

# Load functions
sapply(list.files(pattern = "[.]R$", path = loc_function, full.names = TRUE), source)

```

```{r Simulation specification, include = FALSE}

# Country set
country_set = c("France", "United States")

# Simulation periods
sim = seq(1970, 2080, 10)

# Estimation sample
est_sample = c(1970:2010)

```

```{r Load data, include = FALSE}

# Penn World Table
pwt = read.csv(file.path(loc_final, "pwt.csv"), header = TRUE) %>%
  select("Country", "Year", "emp", "avh", "rgdpna", "rnna", "lab_sh1") %>% 
  subset(Country %in% country_set & Year >= 1970)

# OECD data
oecd = read.csv(file.path(loc_final, "oecd.csv"), header = TRUE) %>% 
  select("Country", "Year", tax_rate = "tax_rev_PC_GDP", union_density = "union_density.lin_inter", union_coverage = "union_coverage.lin_inter") %>% 
  subset(Country %in% country_set & Year >= 1970)

# Demographic data
demo = read.csv(file.path(loc_final, "demo.csv"), header = TRUE) %>% 
  select("Country", "Year", "young", "old", "dep", "n", "p") %>% 
  subset(Country %in% country_set & Year >= 1970)

## Merge
df = merge(merge(pwt, oecd, all = TRUE), demo, all = TRUE)

```

```{r Data retreatment, echo = FALSE}

# Variable modifications
df = df %>%
  group_by(Country) %>% 
  mutate(L = emp * 1000,
         Y = rgdpna / avh * 1000, # AVH control
         K = rnna / avh * 1000, # AVH control
         theta = lab_sh1, # Labor share
         tau = tax_rate / 100, # Tax rate
         u = 1 - L / young, # Unemployment rate
         p1 = lead(p, 40)) %>% 
  select(Country, Year, Ny = young, No = old, n, p, p1, dep, K, L, Y, theta, tau, u) %>% 
  mutate(L = L / first(L), # Normalized labor
         K = K / first(K), # Normalized capital
         Y = Y / first(Y), # Normalized output
         k = K / L, # Normalized capital-labor ratio
         Ny = L / (1-u), # Normalized young population
         No = Ny * dep) %>% # Normalized old population
  ungroup()

# Remove unused countries from Country levels
df$Country = df$Country %>% as.character %>% as.factor()

# Visualization
head(df)

```

## Parameter calibration

```{r Parameter - Dataframe, include = FALSE}

param_base = data.frame("Country" = rep(c("France", "United States"), each = length(sim)),
                   "Year" = sim,
                   "phi" = NA, "sigma" = NA, "a" = NA, "alpha" = (0.99)^40, "gamma" = NA,
                   "omega" = NA, "beta" = NA, A = NA)

```

### Production function

I estimate the elasticity of substitution between capital and labor using the methodology of **Leon-Ledesma, McAdam & Willman (2013)**. Estimation are done for France and United States between 1970 and 2010, using Penn World Table 9.1 data. *For more details, please consult "sigma.md" file.*

```{r Parameter - Production function, echo = FALSE}

# Estimation
ols_sigma = df %>% 
  group_by(Country) %>% 
  mutate(k_log = log(k),
         THETA_log_neg = - log((1-theta)/theta),
         t_diff = Year - first(Year) + 1) %>% 
  select(Country, Year, k_log, THETA_log_neg, t_diff) %>% 
  subset(Year %in% c(1970:2010)) %>% 
  ungroup() %>% 
  lm(k_log ~ Country + THETA_log_neg*Country + t_diff*Country - THETA_log_neg - t_diff, data = .)

# Result visualization
robust.summary(ols_sigma)

# Add production function parameters
param_base = param_base %>% mutate("phi" = rep(1 - df$theta[df$Year == 1970], each = length(sim)),
                 "sigma" = rep(1 / (1 + ols_sigma$coefficients[c((length(country_set)+1):(2*length(country_set)))]), each = length(sim)),
                 "a" = rep(ols_sigma$coefficients[c((2*length(country_set)+1):(3*length(country_set)))], each = length(sim)))


```

### Wage bargaining

I create 4 different specifications of the relative bargaining power of the union.

* *gamma.cst* : Constant value of 0.5. This specification will be used for prediction.
* *gamma0* : Proxy of the bargaining power. It depends on the trade union density and the collective union coverage. I use a square root function to have a concave function of both variables and smooth the variations in bargaining power.
* *gamma1* : Rescale gamma0 such that gamma1 = 0.5 in 1970.
* *gamma2* : Rescale gamma0 such that mean(gamma2) = 0.5.

Both last specifications will be used to improve the quality of the fit on the period 1970 - 2010. Only the first specification will be used for prediction.

```{r Parameter - Bargaining power, include = FALSE}

## Generate different specifications for bargaining power
param.gamma = oecd %>% 
  # subset(Year %in% sim) %>% 
  group_by(Country) %>% 
  mutate(gamma.cst = 0.5,
         gamma0 = sqrt(union_density/100*union_coverage/100),
         gamma1 = gamma0 / first(gamma0) * gamma.cst, # Rescale gamma such that gamma = 0.5 in 1970
         gamma2 = gamma0 / mean(gamma0, na.rm = TRUE) * gamma.cst) %>% # Rescale gamma such that gamma is normalize to its average value on the estimated sample
  merge(param_base[, c("Country", "Year")], ., all.x = TRUE) %>% 
  select(Country, Year, starts_with("gamma")) %>% 
  mutate(gamma.cst = 0.5)

# List gamma specification
gamma_specification = c(".cst", "0", "1", "2")

## Predictions about gamma to be able to run the model
# Constant interpolation
param.gamma[param.gamma$Year ==  2080 ,c("gamma0", "gamma1", "gamma2")] = param.gamma %>%
  subset(Year == 2010) %>%
  select(gamma0, gamma1, gamma2)

param.gamma = param.gamma %>%
  interpol_group(method_use = "constant")

# Visualization
param.gamma


```

### Preferences

According to the specification of $\gamma$, the parameters $\omega$ and $\beta$ are different. Therefore, I compute parameter values for each specification.

```{r Parameter - Preferences, echo = FALSE}

## Generate different parameter values according to the value of gamma
param.pref = df %>%
  subset(Year == 1970) %>% 
  merge(param_base %>% select(Country, Year, phi, sigma, a, alpha), .) %>% 
  merge(param.gamma %>% select(Country, Year, gamma.cst, gamma0, gamma1, gamma2), .) %>% 
  mutate(## Variable : X for each gamma specification
         X.cst = (sigma + (1-phi)/phi*(1-gamma.cst*(1-sigma))/gamma.cst)^(-1),
         X0 = (sigma + (1-phi)/phi*(1-gamma0*(1-sigma))/gamma0)^(-1),
         X1 = X.cst, # X1 is the same as X.cst since gamma1 = 0.5 in 1970
         X2 = (sigma + (1-phi)/phi*(1-gamma2*(1-sigma))/gamma2)^(-1),
         
         ## Parameter : OMEGA
         omega.cst = phi/(1-phi)*n/p*(1+alpha*p1)/(1 + exp(-X.cst)*(Ny - 1)),
         omega0 = phi/(1-phi)*n/p*(1+alpha*p1)/(1 + exp(-X0)*(Ny - 1)),
         omega1 = omega.cst, # omega1 is the same as omega.cst since gamma1 = 0.5 in 1970
         omega2 = phi/(1-phi)*n/p*(1+alpha*p1)/(1 + exp(-X2)*(Ny - 1)),
         
         ## Variable : ETA
         eta.cst = n/p*(1+alpha*p1)/omega.cst,
         eta0 = n/p*(1+alpha*p1)/omega0,
         eta1 = eta.cst, # eta1 is the same as X.cst since gamma1 = 0.5 in 1970
         eta2 = n/p*(1+alpha*p1)/omega2,
         
         ## Parameter : BETA
         beta.cst = 1/(1 - tau)/phi - 1 - eta.cst,
         beta0 = 1/(1 - tau)/phi - 1 - eta0,
         beta1 = beta.cst, # beta1 is the same as omega.cst since gamma1 = 0.5 in 1970
         beta2 = 1/(1 - tau)/phi - 1 - eta2
         ) %>% 
  select(Country, starts_with("omega"), starts_with("beta")) %>% 
  merge(param_base[, c("Country", "Year")], ., all.x = TRUE)

# Visualization
param.pref %>% subset(Year ==  1970) %>% select(-Year)

```

## Simulation

I simulate the model first of all with a different $A$ parameter for each $\gamma$ specification and then with the same $A$ parameter.

```{r Simulation parameters specification, include = FALSE}

init_seq = seq(1970, 2000, 10)

# Baseline data
data_base = df %>% group_by(Country) %>% subset(Year %in% sim) %>% select(Country, Year, Ny, No, n, p, p1, K) %>% 
  mutate(Sequence = ((sim- 1970)/10)%%4+1,
         Period = (sim-init_seq)/40+1,
         Ny = ifelse(Year == 2010, NA, Ny),
         No = ifelse(Year == 2010, NA, No),
         K = ifelse(Year == 2010, NA, K),
         # Complete NA values for p1 in 2070 and 2080
         p1 = ifelse(Year >= 2070, p1[Year == 2060] + (Year - 2060)/10 * mean(p1/lag(p1)-1, na.rm = T), p1), 
         ## Create empty variables
         eta = NA, AK = NA, AL = NA, k1 = NA, k2 = NA, k = NA, X = NA, L = NA, w = NA, Y = NA, u = NA,
         theta = NA, tau = NA, b = NA, h = NA, S = NA) 

# Re-order variables
data_base = data_base %>% select(Country, Year, Sequence, Period, Ny, No, n, p, p1, eta, AK, AL,
                                 k1, k2, k, X, L, w, Y, u, theta, tau, b, h, S, K)
  
# Visualization
head(data_base)

```


```{r Population dynamics, include = FALSE}

# Prepare base datasets
data = data_base
param = param_base

## No biased technical change
data$AK = 1
data$AL = 1

## Population dynamics
for(seq in 1:4){
  for(t in 2:3){
    # Young population dynamics
    data$Ny[data$Period == t & data$Sequence == seq] = data$Ny[data$Period == t-1 & data$Sequence == seq] *
      data$n[data$Period == t & data$Sequence == seq]
    # Old population dynamics
    data$No[data$Period == t & data$Sequence == seq] = data$Ny[data$Period == t-1 & data$Sequence == seq] *
      data$p[data$Period == t & data$Sequence == seq]
  }
}
rm(seq, t)

```

### Different scale parameter (A)

```{r Gamma specification, include = FALSE}

# Initialize final dataset for gamma comparison
final_gamma = data.frame(matrix(ncol = ncol(data)+ ncol(param) -2 + 1, nrow = 0)) %>%
  setNames(c("Specification", names(data), names(param)[-c(1,2)]))

# Data save
data_save = data

for(gamma_spe in gamma_specification){
  
  # Specification of the model
  spe = gamma_spe
  
  data = data_save %>% 
    # Re-initialize data and define specification of the model
    mutate(Specification = spe) %>% 
    # Select gamma / omega / beta : choose between ".cst" / "0" / "1" / "2"
    gob_finder(param, gamma_specification = gamma_spe) %>% 
    # Compute eta
    mutate(eta = n / p *( 1 + alpha * p1) / omega) %>% 
    # Put Specification as 1st column
    select(Specification, everything())
  
  # A finder
  source("./script/sim_AFinder.R")
  
  # Empty dataframe for results
  result = data.frame(matrix(ncol = ncol(data), nrow = 0)) %>%
    setNames(names(data))
  
  # Simulate model for country_set
  for(country in country_set){
    
    result = data %>%
      subset(Country == country) %>% 
      model(time = 2) %>% 
      rbind(result, .)
    
  }
  
  # Regroup results
  final_gamma = rbind(final_gamma, result)
  
}

# Write final_gamma
write.csv(final_gamma, file.path(loc_sim, "final_gamma.csv"), row.names = FALSE)

```

```{r Gamma analysis, echo = FALSE}

final_gamma %>% 
  select(Specification, Country, Year, theta) %>% 
  subset(Year %in% seq(1970, 2010, 10)) %>% 
  
  ggplot(aes(x = Year, y = theta, color = Specification)) +
  geom_line(size = 0.5) +
  facet_wrap(Country ~ ., scale = "free") +
  theme_classic() +
  theme(legend.position = "bottom", legend.direction = "horizontal") +
  labs(x = "Year", y = "Labor share")

```

Decreasing $\gamma$ does not improve the model performance. Prediction are almost the same whatever the specification.

### Same scale parameter (A)

```{r Gamma specification with same A, include = FALSE}

# Initialize final dataset for gamma comparison
final_gamma2 = data.frame(matrix(ncol = ncol(data)+ ncol(param) -2 + 1, nrow = 0)) %>%
  setNames(c("Specification", names(data), names(param)[-c(1,2)]))

for(gamma_spe in gamma_specification){
  
  # Specification of the model
  spe = gamma_spe
  
  data = data_save %>% 
    # Re-initialize data and define specification of the model
    mutate(Specification = spe) %>% 
    # Select gamma / omega / beta : choose between ".cst" / "0" / "1" / "2"
    gob_finder(param, gamma_specification = gamma_spe) %>% 
    # Compute eta
    mutate(eta = n / p *( 1 + alpha * p1) / omega) %>% 
    # Put Specification as 1st column
    select(Specification, everything())
  
  # No AFinder, same A for all specification
  data$A = rep(c(25.777, 33.000), each = 12)
  
  # Empty dataframe for results
  result = data.frame(matrix(ncol = ncol(data), nrow = 0)) %>%
    setNames(names(data))
  
  # Simulate model for country_set
  for(country in country_set){
    
    result = data %>%
      subset(Country == country) %>% 
      model(time = 2) %>% 
      rbind(result, .)
    
  }
  
  # Regroup results
  final_gamma2 = rbind(final_gamma2, result)
  
}

# Write final_gamma2
write.csv(final_gamma2, file.path(loc_sim, "final_gamma2.csv"), row.names = FALSE)

```

```{r Gamma analysis with same A, echo = FALSE}

final_gamma2 %>% 
  select(Specification, Country, Year, theta) %>% 
  subset(Year %in% seq(1970, 2010, 10)) %>% 
  
  ggplot(aes(x = Year, y = theta, color = Specification)) +
  geom_line(size = 0.5) +
  facet_wrap(Country ~ ., scale = "free") +
  theme_classic() +
  theme(legend.position = "bottom", legend.direction = "horizontal") +
  labs(x = "Year", y = "Labor share")
```

Decreasing $\gamma$ does not improve the model performance. Prediction are almost the same whatever the specification.

## Conclusion

Changing $\gamma$ does not improve the results. Relative bargaining power has a small impact in the model prediction. However, it may mean that the outside option is the key determinant to improve model predictions.


























