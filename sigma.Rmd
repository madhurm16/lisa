---
title: "Capital-Labor elasticity of substitution"	
author: "Fabien Petit"	
date: "24/05/2019"	
output:	
  github_document:	
    pandoc_args: --webtex
---

```{r Init, include = FALSE}	

# Define required packages
require(dplyr) # The FAMOUS one
require(reshape2) # Reshape data frame
require(ggplot2) # Plot
require(bucky) # Robust standard errors
require(sandwich) # If you are hungry
require(strucchange) # Chow cacao

# Define paths
loc_final = file.path("data", "final")
loc_result_sigma = file.path("result", "sigma")

# Define country set
# country_set = c("Australia", "Canada", "France", "Italy", "Japan", "United States")
country_set = c("France", "United States")

# Graphic parameter
scale_graph = 1920/1080

```	

## Methodology

I estimate the elasticity of substitution between capital and labor using the methodology of **Leon-Ledesma, McAdam & Willman (2013)**. Estimation are done for France and United States between 1970 and 2010, using Penn World Table 9.1 data.

Following the methodology of Leon-Ledesma, McAdam & Willman (2013), I estimate the following equation :	
<center>
$$\ln k_t = \alpha - \frac{\sigma}{1-\sigma} \ln \Theta_t + \left( a_L-a_K\right)t + \varepsilon_t$$
</center>
Therefore, I need to compute the capital-to-labor ratio $~k_t~$ and the capital-to-labor income ratio $~\Theta_t~$.

## Data

```{r Load PWT data}	

pwt = read.csv(file.path(loc_final, "pwt.csv"), header = TRUE) %>%
  subset(Country %in% country_set &
           Year %in% c(1970:2010) & i_labsh2 == 1) %>%
  select("Country", "Year", "pop", "emp", "avh", "rnna", "lab_sh1", "lab_sh2")

head(pwt)
 
```	

The variables from the **Penn World Table 9.1** are the following :	

* *pop* : Population (in millions.)	
* *emp* : Number of persons engaged (in millions)	
* *avh* : Average annual hours worked by persons engaged	
* *rnna* : Capital stock at constant 2011 national prices (in mil. 2011US$)	
* *lab_sh1* : Share of labour compensation in GDP at current national prices (**Adjustment method 1**)
* *lab_sh2* : Share of labour compensation in GDP at current national prices (**Adjustment method 2**)

```{r Compare both labor share, echo = FALSE}

pwt %>% select(Country, Year, lab_sh1, lab_sh2) %>% 
  melt(id.vars = c("Country", "Year")) %>% 
  ggplot(aes(x = Year, y = value, color = variable)) +
  scale_color_discrete(name = "Adjustment Method", breaks = c("lab_sh1", "lab_sh2"),
                       labels = c("1st", "2nd")) +
  geom_line(size = 0.5) +
  facet_wrap(Country ~ .) +
  labs(x = "Year", y = "Labor share") +
  theme_classic() +
  theme(legend.direction = "horizontal", legend.position = "bottom")


```


I use the first adjustment method (see **Frenstra, Inklaar and Timmer 2015** and **Gollin 2002** for more details). An adjustment method is required to take into account self-employed income.

**Adjustment 1** adds mixed income (MIX) to the compensation of employees (COMP). Thus,
<center>
$$LS = \frac{COMP+MIX}{GDP}$$
</center>

**Adjustment 2** assumes the same labor share for mixed income as for the rest of the economy. Thus,
<center>
$$LS = \frac{COMP}{GDP-MIX}$$
</center>

In the model, workers are only young individuals and provide only labor supply. Therefore, I assume that self-employed people earn an income that is characterized as a compensation. Hence, I will use the first adjustment method.

```{r Variable computation, echo = FALSE}

# Capital in the economy (K)	
pwt$K = pwt$rnna * 1000
# Capital in the economy (K) // Corrected for hours worked	
pwt$K.avh_correct = pwt$rnna * 1000 / pwt$avh

# Labor in the economy (L)
pwt$L = pwt$emp * 1000

# Capital-to-labor ratio (k)	
pwt$k = pwt$K / pwt$L
# Capital-to-labor ratio (k) // Corrected for hours workers	
pwt$k.avh_correct = pwt$K.avh_correct / pwt$L

# Capital-to-labor income ratio (THETA) // 1st Adjustment method
pwt$THETA1 = (1-pwt$lab_sh1)/pwt$lab_sh1

# Capital-to-labor income ratio (THETA) // 2nd Adjustment method
pwt$THETA2 = (1-pwt$lab_sh2)/pwt$lab_sh2

```

I normalize the capital-to-labor ratio to the initial year (i.e. 1970).

```{r Normalization, echo = FALSE}

# Normalize to initial year
pwt = pwt %>%
  group_by(Country) %>%
  mutate(K_nor = K / first(K),
         K_nor.avh_correct = K.avh_correct / first(K.avh_correct),
         L_nor = L / first(L),
         k_nor = K_nor / L_nor,
         k_nor.avh_correct = K_nor.avh_correct / L_nor) %>%
  ungroup()

```	


```{r Plot k_nor, echo = FALSE}

pwt %>% select("Country", "Year", "k_nor", "k_nor.avh_correct") %>%
  melt(id.vars = c("Country", "Year")) %>%
  ggplot(aes(x = Year, y = value, color = variable)) +
  geom_line(size = .5) +
  facet_wrap(Country ~ .) +
  scale_color_discrete(name = "", breaks = c("k_nor", "k_nor.avh_correct"),
                       labels = c("Standard", "AVH correction")) +
  labs(x = "Year", y = "Normalized capital-to-labor ratio (1970 = 1)") +
  theme_classic(base_size = 14) +
  theme(legend.direction = "horizontal", legend.position = "bottom")
  
```	

```{r TEST }
pwt_test = pwt %>%
  group_by(Country) %>%
<<<<<<< HEAD
  subset(Year %in% c(1970:2010)) %>% 
=======
>>>>>>> 10f8d25918c93aeafc234a919b99829ecbd05c1b
  mutate(k_nor_log = log(k_nor),
         k_nor_log.avh_correct = log(k_nor.avh_correct),
         THETA1_log = log(THETA1),
         THETA2_log = log(THETA2),
         t = Year - first(Year),
         wr.1avh = k_nor.avh_correct/THETA1,
         log_wr.1avh = log(wr.1avh),
         THETA1_log_neg = - THETA1_log) %>%
  ungroup()

# Regressions

# RAW
ols.raw = pwt_test %>%
  lm(formula = THETA1_log_neg ~ Country + k_nor*Country - 1 - k_nor)
summary(ols.raw)

# HOURS
ols.hours = pwt_test %>%
  lm(formula = THETA1_log_neg ~ Country + k_nor_log*Country - 1 - k_nor_log)
summary(ols.hours)

# BTC
ols.btc = pwt_test %>%
  lm(formula = THETA1_log_neg ~ Country + k_nor*Country + t*Country - 1 - k_nor - t)
summary(ols.btc)

# BTC + HOURS
ols.both = pwt_test %>%
  lm(formula = THETA1_log_neg ~ Country + k_nor_log*Country + t*Country - 1 - k_nor_log - t, data = .)
summary(ols.both)
<<<<<<< HEAD

=======
<<<<<<< HEAD
>>>>>>> d3e00905e8a6162df0766fcd8820bac95c257030
```


```{r TEST }
=======












>>>>>>> 10f8d25918c93aeafc234a919b99829ecbd05c1b
# Robust standard errors
robustify(ols.test) %>% summary()
# Compute the associated sigma
1/
  (1+ols.test$coefficients[c((length(country_set)+1):(2*length(country_set)))])

pwt_test %>% 
  select(Country, Year, k_nor_log, THETA1_log_neg) %>%  
  melt(id.vars = c("Country", "Year")) %>% 
  
  ggplot(aes(x = Year, y = value, color = variable)) +
  geom_line() +
  facet_wrap(Country ~ .) +
  theme_classic(base_size = 14)
```


```{r TEST }
## Break in 82 for France
pwt_break = pwt_test %>% 
  select(Country, Year, k_nor_log.avh_correct, THETA1_log_neg, t)

pwt_break = pwt_break %>% 
  mutate(THETA1_log_neg_detrend = lm(THETA1_log_neg ~ t*Country, data = .) %>% residuals(),
         k_nor_log.avh_correct_detrend = lm(k_nor_log.avh_correct ~ t*Country, data = .) %>% residuals())

pwt_break %>% 
  select(Country, Year, k_nor_log.avh_correct_detrend, THETA1_log_neg_detrend) %>% 
  melt(id.vars = c("Country", "Year")) %>% 
  
  ggplot(aes(x = Year, y = value, color = variable)) +
  geom_line() +
  facet_wrap(Country ~ .) +
  theme_classic(base_size = 14) +
  theme(legend.position = "none")
```


```{r TEST }
# Break Year
break_year = 1981

# Before
ols.before = pwt_break %>% 
  subset(Year < break_year) %>% 
  lm(formula = THETA1_log_neg_detrend ~ Country + k_nor_log.avh_correct_detrend*Country - k_nor_log.avh_correct_detrend  - 1)
robustify(ols.before) %>% summary()
1/
  (1+ols.before$coefficients[c((length(country_set)+1):(2*length(country_set)))])

# After
ols.after = pwt_break %>% 
  subset(Year >= break_year) %>% 
  lm(formula = THETA1_log_neg_detrend ~ Country + k_nor_log.avh_correct_detrend*Country - k_nor_log.avh_correct_detrend  - 1)
robustify(ols.after) %>% summary()
1/ (1+ols.after$coefficients[c((length(country_set)+1):(2*length(country_set)))])





```


```{r Log variables, echo = FALSE}

# Variable modification for estimation	
pwt = pwt %>%
  group_by(Country) %>%
  mutate(k_nor_log = log(k_nor),
         k_nor_log.avh_correct = log(k_nor.avh_correct),
         THETA1_log_neg = -log(THETA1),
         THETA2_log_neg = -log(THETA2),
         t = Year - first(Year)) %>%
  ungroup()

# Plot logs

pwt %>% select("Country", "Year", "k_nor_log", "k_nor_log.avh_correct",
               "THETA1_log_neg", "THETA2_log_neg") %>%
  melt(id.vars = c("Country", "Year")) %>% 
  mutate(kap = ifelse(grepl("k", variable), "k", "theta"),
         best = ifelse(grepl("THETA1|avh", variable), "first", "second" )) %>% 
  ggplot(aes(x = Year, y = value, color = kap, linetype =  best)) +
  geom_line(size = .5) +
  facet_wrap(Country ~ .) +
  scale_color_discrete(name = "", breaks = c("k", "theta"),
                       labels = c("Normalized capital-labor ratio (log)",
                                  "Labor-capital income ratio (log)")) +
  scale_linetype_discrete(name = "", breaks = c("first", "second"),
                          labels = c("Adjustment method 1 or AVH control",
                                     "Adjustment method 2 or no control")) +
  labs(x = "Year", y = "") +
  theme_classic(base_size = 14) +
  theme(legend.direction = "vertical", legend.position = "top")
  

```

## Estimation

I estimate four versions of the elasticity of substitution :

* Without any control
* Control for biased technical change (BTC)
* Control for average hours worked (AVH)
* Control for BTC and AVH

### No controls

```{r Regression - pwt.no}

## THETA 1

# Regression : no control
ols1.no = pwt %>%
  lm(formula = k_nor_log ~ Country + THETA1_log_neg*Country - THETA1_log_neg -1)
# Robust standard errors
ols1.no = robustify(ols1.no) %>% 
  summary()
# Compute the associated sigma
pwt1.no = ols1.no$coefficients[c((length(country_set)+1):(2*length(country_set)))]/(1+ols1.no$coefficients[c((length(country_set)+1):(2*length(country_set)))])
# Visualize summary
ols1.no

## THETA 2

# Regression : no control
ols2.no = pwt %>%
  lm(formula = k_nor_log ~ Country + THETA2_log_neg*Country - THETA2_log_neg -1)
# Robust standard errors
ols2.no = robustify(ols2.no) %>% 
  summary()
# Compute the associated sigma
pwt2.no = ols2.no$coefficients[c((length(country_set)+1):(2*length(country_set)))]/(1+ols2.no$coefficients[c((length(country_set)+1):(2*length(country_set)))])
# Visualize summary
ols2.no

```

### BTC control

```{r Regression - pwt.btc}

## THETA 1

# Regression : control only for biased technical change
ols1.btc = pwt %>%
  lm(formula = k_nor_log ~ Country + THETA1_log_neg*Country + Country*t - THETA1_log_neg -1 - t)
# Robust standard errors
ols1.btc = robustify(ols1.btc) %>%
  summary()
# Compute the associated sigma
pwt1.btc = ols1.btc$coefficients[c((length(country_set)+1):(2*length(country_set)))]/(1 + ols1.btc$coefficients[c((length(country_set)+1):(2*length(country_set)))])
# Visualize summary
ols1.btc

## THETA 2

# Regression : control only for biased technical change
ols2.btc = pwt %>%
  lm(formula = k_nor_log ~ Country + THETA2_log_neg*Country + Country*t - THETA2_log_neg -1 - t)
# Robust standard errors
ols2.btc = robustify(ols2.btc) %>%
  summary()
# Compute the associated sigma
pwt2.btc = ols2.btc$coefficients[c((length(country_set)+1):(2*length(country_set)))]/(1 + ols2.btc$coefficients[c((length(country_set)+1):(2*length(country_set)))])
# Visualize summary
ols2.btc

```

### AVH control

```{r Regression - pwt1.avh}

## THETA 1

# Regression : control only for hours worked
ols1.avh = pwt %>%
  lm(formula = k_nor_log.avh_correct ~ Country + THETA1_log_neg*Country - THETA1_log_neg -1)
# Robust standard errors
ols1.avh = robustify(ols1.avh) %>% 
  summary()
# Compute the associated sigma
pwt1.avh = ols1.avh$coefficients[c((length(country_set)+1):(2*length(country_set)))]/(1 + ols1.avh$coefficients[c((length(country_set)+1):(2*length(country_set)))])
# Visualize summary
ols1.avh

## THETA 2

# Regression : control only for hours worked
ols2.avh = pwt %>%
  lm(formula = k_nor_log.avh_correct ~ Country + THETA2_log_neg*Country - THETA2_log_neg -1)
# Robust standard errors
ols2.avh = robustify(ols2.avh) %>% 
  summary()
# Compute the associated sigma
pwt2.avh = ols2.avh$coefficients[c((length(country_set)+1):(2*length(country_set)))]/(1 + ols2.avh$coefficients[c((length(country_set)+1):(2*length(country_set)))])
# Visualize summary
ols2.avh

```

### AVH/BTC controls

```{r Regression - pwt1.avh.btc}

## THETA 1

# Regression : control for both hours worked and biased technical change
ols1.avh.btc = pwt %>%
  lm(formula = k_nor_log.avh_correct ~ Country + THETA1_log_neg*Country + t*Country - THETA1_log_neg -1 - t)
# Robust standard errors
ols1.avh.btc = robustify(ols1.avh.btc) %>% 
  summary()
# Compute the associated sigma
pwt1.avh.btc = ols1.avh.btc$coefficients[c((length(country_set)+1):(2*length(country_set)))]/(1 + ols1.avh.btc$coefficients[c((length(country_set)+1):(2*length(country_set)))])
# Visualize summary
ols1.avh.btc

## THETA 2

# Regression : control for both hours worked and biased technical change
ols2.avh.btc = pwt %>%
  lm(formula = k_nor_log.avh_correct ~ Country + THETA2_log_neg*Country + t*Country - THETA2_log_neg -1 - t)
# Robust standard errors
ols2.avh.btc = robustify(ols2.avh.btc) %>% 
  summary()
# Compute the associated sigma
pwt2.avh.btc = ols2.avh.btc$coefficients[c((length(country_set)+1):(2*length(country_set)))]/(1 + ols2.avh.btc$coefficients[c((length(country_set)+1):(2*length(country_set)))])
# Visualize summary
ols2.avh.btc

```	

### Summary of the results

I gather all estimated $\hat{\sigma}$. Without control for biased technical change (BTC), I obtain negative $\hat{\sigma}$, which is not possible. Once I control for BTC, I obtain a positive elasticity without control on the average hours worked (AVH). United States elasticity is below one but not significantly different from 1. This case is the Cobb-Douglas specification. However, without correcting by hours worked I generate a bias toward Cobb-Douglas for both countries. Finally, on the last estimate, with BTC and AVH controls, I obtain a capital-labor elasticity of substitution of 1.356 for France and 1.224 for United States (see table below).
With the second adjustment method, estimates are still biased toward 1 when I do not control for AVH. However, once done, the elasticity is close to 1 for France (i.e. 1.047) and larger for the US (i.e. 1.329).

```{r PWT - Gather sigma, echo = FALSE}

# Regroup all estimated sigma
pwt_est = data.frame("Country" = country_set, pwt1.no, pwt1.btc, pwt1.avh, pwt1.avh.btc,
                     pwt2.no, pwt2.btc, pwt2.avh, pwt2.avh.btc) %>%
  melt(id.vars = "Country") %>%
  mutate(btc = ifelse(grepl(pattern = "btc", variable), 1, 0),
         avh = ifelse(grepl(pattern = "avh", variable), 1, 0),
         adj = ifelse(grepl(pattern = "1", variable), 1, 2),
         data = "pwt") %>%
  select("Country", "data", "btc", "avh", "adj", "value")

# Visualization
pwt_est

```	

## Break Year

The purpose of this section is to investigate whether there is a break in the estimated elasticity of substitution. In particular for France. Indeed, there capital-per-worker $k_t$ grows at a relatively constant rate while the labor share $\Theta_t$ faces a huge decrease during the 80's.

I consider only France with adjustment method 1 and capital with average hours worked correction. Estimation is done with biased technical change.

```{r Break Year - Dataset, echo = FALSE}

# Define data frame
pwt_break = pwt %>% 
  subset(Year %in% c(1970:2010) & Country == "France") %>% 
  select(Country, Year, k_nor_log.avh_correct, THETA1_log_neg, t) %>% 
  setNames(c("Country", "Year", "k_nor_log", "THETA_log_neg", "t")) %>% 
  mutate(t2 = t^2)

```

```{r Break Year - Plot, echo = FALSE}

pwt_break %>% 
  select(Country, Year, k_nor_log, THETA_log_neg) %>% 
  melt(id.vars = c("Country", "Year")) %>% 
  
  ggplot(aes(x = Year, y = value, color = variable)) +
  geom_line() +
  geom_vline(xintercept = 1983, linetype = "dashed") +
  scale_color_manual(values = brewer.pal(8, "Set1")) +
  scale_x_continuous(breaks = c(1970, 1980, 1983, 1990, 2000, 2010)) +
  theme_classic(base_size = 14) +
  labs(x = "", y = "") +
  theme(legend.position = "none") +
  ggsave(file.path(loc_result_sigma, "k_Theta_log.png"), width = scale_graph*5, height = scale_graph*5/2)

```

```{r Break Year - Correlation, echo = FALSE}

# 1983 included in after
pwt_break %>% 
  mutate(period = ifelse(Year < 1983, "before", "after")) %>% 
  group_by(period) %>% 
  summarise(cor(k_nor_log, THETA_log_neg))

# 1983 included in before
pwt_break %>% 
  mutate(period = ifelse(Year <= 1983, "before", "after")) %>% 
  group_by(period) %>% 
  summarise(cor(k_nor_log, THETA_log_neg))


```


This is the baseline regression, where I estimate the capital-labor elasticity of substitution for the whole sample. 

```{r Break Year - Baseline estimation, echo = FALSE}

ols_base = pwt_break %>% 
  lm(k_nor_log ~ THETA_log_neg + t, data = .)
robust.summary(ols_base)

```

There is a biased technical change, which is constant and significant. I have to keep the same rate of technical change. Because if I split the sample, I would obtain two different BTC growth rates. Thus, a way is to detrend the capital-per-worker and the capital-to-labor income ratio. Such a methodology comes from the **Frisch–Waugh–Lovell theorem**.


```{r Break Year - Detrend, echo = FALSE}

# Detrend k
pwt_break$k_nor_log_detrend = pwt_break %>% 
  lm(k_nor_log ~ t, data = .) %>%
  residuals()

# Detrend THETA
pwt_break$THETA_log_neg_detrend = pwt_break %>% 
  lm(THETA_log_neg ~ t, data = .) %>%
  residuals()

# Plot detrended variables
pwt_break %>% 
  select(Year, k_nor_log_detrend, THETA_log_neg_detrend) %>% 
  melt(id.vars = "Year") %>% 
  
  ggplot(aes(x = Year, y = value, color = variable)) +
  geom_line() +
  geom_vline(xintercept = 1982, linetype = "dashed") +
  geom_vline(xintercept = 1985, linetype = "dashed") +
  geom_vline(xintercept = 1989, linetype = "dashed") +
  scale_color_manual(values = brewer.pal(8, "Set1")) +
  scale_x_continuous(breaks = c(1970, 1982, 1985, 1989, 2000, 2010)) +
  theme_classic(base_size = 14) +
  labs(x = "", y = "") +
  theme(legend.position = "none") +
  ggsave(file.path(loc_result_sigma, "k_Theta_log_detrend.png"), width = scale_graph*5, height = scale_graph*5/2)

```

This is an example of the regressions when I break the sample in 1985.

```{r Break Year - Plot regimes, echo = FALSE}

pwt_break %>% 
  select(Year, k_nor_log_detrend, THETA_log_neg_detrend) %>% 
  mutate(before_break = as.factor(ifelse(Year < 1985, "1970-1984", "1985-2010"))) %>% 
  
  ggplot(aes(x = k_nor_log_detrend, y = THETA_log_neg_detrend, color = before_break)) +
  geom_point() +
  stat_smooth(method = "lm", alpha = 0.2) +
  # stat_smooth(method = "lm", color = "black") +
  scale_color_manual(name = "", values = brewer.pal(8, "Set1")[c(3,4)]) +
  theme_classic(base_size = 14) +
  labs(x = "", y = "") +
  theme(legend.direction = "vertical", legend.box = "horizontal", 
          legend.position = c(0.02,1), legend.justification = c(0,1)) +
  ggsave(file.path(loc_result_sigma, "k_Theta_log_reg85.png"), width = scale_graph*5, height = scale_graph*5/2)

```

It seems that there are two regimes. There are three main potential breaks around the years 1983, 1985 and 1989. 

```{r Break Year - Max k , echo = FALSE}

# Find the max of the red curve
pwt_break %>% 
  subset(k_nor_log_detrend == max(k_nor_log_detrend) | 
           THETA_log_neg_detrend == max(THETA_log_neg_detrend) |
           THETA_log_neg_detrend == min(THETA_log_neg_detrend))

```

However, the break may have occur during the 80's. I have to determine which year optimize the split. To do so, I use a grid-search approach between 1980 and 1990. Below is the baseline regression leading to an elasticity of 1.356.


```{r Break Year - Baseline Regression, echo = FALSE}
# Baseline estimate
ols_base_detrend = pwt_break %>% 
  lm(k_nor_log_detrend ~ THETA_log_neg_detrend -1, data = .)
ols_base_detrend = robust.summary(ols_base_detrend)

# Visualization
ols_base_detrend

# p value of the baseline estimation
p_baseline = ols_base_detrend$coefficients[4]
```

I run a regression for each subsample, the subsample are separated with a break year between 1980 and 1990. Then, I repeat this for each break year on this interval. I report on the graph below the p-values of both regressions according to the break year considered. I only show those where both p-values do not exceed the one of the baseline regression.

```{r Break Year - Split loop, echo = FALSE}
df_break = data.frame(matrix(nrow = 0, ncol = 5)) %>% 
  setNames(c("splitter", "sigma_before", "p_before", "sigma_after", "p_after"))

for(splitter in c(1979:1990)){
  
  # Before spliter
  ols_before = pwt_break %>% 
    subset(Year < splitter) %>% 
    lm(k_nor_log_detrend ~ THETA_log_neg_detrend -1, data = .)
  ols_before = robust.summary(ols_before)

  # After spliter
  ols_after = pwt_break %>% 
    subset(Year >= splitter) %>% 
    lm(k_nor_log_detrend ~ THETA_log_neg_detrend -1, data = .)
  ols_after = robust.summary(ols_after)
  
  # Gather results
  result_break = t(c(splitter,
                   1/(1+ols_before$coefficients[1]),
                   ols_before$coefficients[4],
                   1/(1+ols_after$coefficients[1]),
                   ols_after$coefficients[4]))
  
  # Add to final dataframe
  df_break = df_break %>% rbind(result_break)
  
}

df_break = df_break %>% 
  setNames(c("splitter", "sigma_before", "p_before", "sigma_after", "p_after"))
<<<<<<< HEAD

df_break
```

=======

df_break
```

<<<<<<< HEAD
=======
>>>>>>> 10f8d25918c93aeafc234a919b99829ecbd05c1b

>>>>>>> d3e00905e8a6162df0766fcd8820bac95c257030
```{r Break Year - Split Graph, echo = FALSE}
df_break %>% 
  select(splitter, p_before, p_after) %>%
  melt(id.vars = "splitter") %>% 
  
  ggplot(aes(x = splitter, y = value, color = variable)) +
  geom_line() +
  geom_hline(yintercept = p_baseline, linetype = "dashed") +
  scale_y_continuous(name = "p-value", limits = c(NA, p_baseline)) +
  scale_x_continuous(name = "Break year", breaks = c(1979:1990)) +
  scale_color_discrete(name = "Regression", breaks = c("p_before", "p_after"),
                       labels = c("Before", "After")) +
  theme_classic()


```

Therefore, all the break years above are candidate. However, there is another condition within the model that ensure a positive wage and capital-to-labor ratio at the equilibrium. This condition is that $− \log^{-1}(x_t) > \sigma$ where $x_t$ is the unemployment replacement rate at time $t$ from data. As long as $\sigma$ is lower than 1, this condition is satisfied. However, the issue raises when $\sigma$ is greater than one and thus after the break year. So I also have to filter the $\sigma$ candidates with this condition. For more details about this condition, see the file *xsigmacdt.md*.

```{r Break Year - Condition on sigma, echo = FALSE}

# Import data from CWED
cwed = read.csv(file.path(loc_final, "cwed.csv"), header = TRUE)

# Keep only France and US100.lin_inter and merge with df_break
cwed = cwed %>% 
  subset(Country == "France" & Year %in% c(1970:2010)) %>% 
  select(Year, US100.lin_inter)

# Find the min of the unemployment replacement rate for the subsample after the break year
for(i in c(1:41)){
cwed$x_min[i] = cwed %>% subset(Year >= 1969+i) %>% pull("US100.lin_inter") %>% min(na.rm = TRUE)
}

# Compute the larger sigma allowed for each sub sample
cwed = cwed %>% 
  select(Year, x_min) %>% 
  mutate(sigma_bar = -log(x_min)^(-1))

# Merge with df_break
df_break = df_break %>% merge(cwed, by.x = "splitter", by.y = "Year") %>% 
  mutate(pvalue_ok = ifelse(p_before < p_baseline & p_after < p_baseline, TRUE, FALSE),
         xcdt_ok = ifelse(sigma_after < sigma_bar, TRUE, FALSE),
         break_point = pvalue_ok & xcdt_ok)

# Visualization
df_break

```

Hence, only the break in 1982 complies with the condition to ensure an equilibrium with positive wage and capital-to-labor ratio. Thus, instead of using a unique capital-labor elasticity of substitution of 1.356, I estimate two elasticity of substitution one before 1982 and therafter with specific biased technical change for each sub sample.


```{r Break Year - Without BTC, echo = FALSE}

# Before
ols_before.raw = pwt_break %>% 
  subset(Year < 1982) %>% 
  lm(k_nor_log ~ THETA_log_neg + t, data = .)
robust.summary(ols_before.raw)

# After
ols_after.raw = pwt_break %>% 
  subset(Year >= 1982) %>% 
  lm(k_nor_log ~ THETA_log_neg + t, data = .)
robust.summary(ols_after.raw)


```



